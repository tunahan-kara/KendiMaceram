package com.kendimaceram.app.data

import android.content.Context
import android.media.AudioAttributes
import android.media.AudioFormat
import android.media.AudioTrack
import android.util.Log
import ai.onnxruntime.OnnxTensor
import ai.onnxruntime.OrtEnvironment
import ai.onnxruntime.OrtSession
import dagger.hilt.android.qualifiers.ApplicationContext
import kotlinx.coroutines.CoroutineScope
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.launch
import java.nio.ByteBuffer
import java.nio.ByteOrder
import java.nio.FloatBuffer
import java.nio.LongBuffer
import javax.inject.Inject
import javax.inject.Singleton

private const val TAG = "KokoroTtsEngine"

@Singleton
class OnDeviceTtsEngine @Inject constructor(
    @ApplicationContext private val context: Context
) {
    private val ortEnvironment: OrtEnvironment = OrtEnvironment.getEnvironment()
    private lateinit var ttsSession: OrtSession
    private lateinit var tokenizer: Tokenizer
    private var audioTrack: AudioTrack? = null

    var isInitialized = false
        private set

    init {
        CoroutineScope(Dispatchers.IO).launch {
            try {
                Log.d(TAG, "Kokoro TTS Modeli y√ºkleniyor...")
                ttsSession = createSession("model_q8f16.onnx")
                Log.d(TAG, "‚úÖ Kokoro modeli y√ºklendi.")
                Log.d(TAG, "Tokenizer ba≈ülatƒ±lƒ±yor...")
                tokenizer = Tokenizer(context)
                Log.d(TAG, "‚úÖ Tokenizer ba≈ülatƒ±ldƒ±.")
                isInitialized = true
                Log.d(TAG, "üöÄ Motor hazƒ±r!")
            } catch (e: Exception) {
                Log.e(TAG, "‚ùå Model veya Tokenizer y√ºklenirken bir hata olu≈ütu!", e)
            }
        }
    }

    private fun createSession(modelName: String): OrtSession {
        val modelBytes = context.assets.open(modelName).readBytes()
        return ortEnvironment.createSession(modelBytes)
    }

    fun synthesize(text: String) {
        if (!isInitialized) {
            Log.e(TAG, "Motor hen√ºz hazƒ±r deƒüil.")
            return
        }

        CoroutineScope(Dispatchers.IO).launch {
            try {
                Log.d(TAG, "Sentezleme ba≈ülƒ±yor: '$text'")

                // 1. Metni sayƒ±lara √ßevir (Tokenizer)
                val inputIds = tokenizer.tokenize(text)
                val inputShape = longArrayOf(1, inputIds.size.toLong())
                val inputBuffer = LongBuffer.wrap(inputIds)
                val inputTensor = OnnxTensor.createTensor(ortEnvironment, inputBuffer, inputShape)

                // 2. Ses stilini (speaker embedding) dosyadan oku
                val voiceBytes = context.assets.open("am_michael.bin").readBytes()
                val voiceBuffer = ByteBuffer.wrap(voiceBytes).order(ByteOrder.LITTLE_ENDIAN).asFloatBuffer()
                // Python'daki gibi belirli bir indeksi almak yerine, ilk ses √∂rneƒüini (ilk 256 float) alƒ±yoruz
                val styleFloats = FloatArray(256)
                voiceBuffer.get(styleFloats)
                val styleTensor = OnnxTensor.createTensor(
                    ortEnvironment,
                    FloatBuffer.wrap(styleFloats),
                    longArrayOf(1, 256)
                )

                // 3. Hƒ±z (speed) girdisini olu≈ütur
                val speedTensor = OnnxTensor.createTensor(
                    ortEnvironment,
                    FloatBuffer.wrap(floatArrayOf(1.0f)),
                    longArrayOf(1)
                )

                // Girdileri, Python √∂rneƒüindeki doƒüru isimlerle bir Map'e koyuyoruz.
                val inputs = mapOf(
                    "input_ids" to inputTensor,
                    "style" to styleTensor,
                    "speed" to speedTensor
                )

                // Modeli √ßalƒ±≈ütƒ±r
                val results = ttsSession.run(inputs)
                val audioData = results.use { (it.get(0) as OnnxTensor).floatBuffer.array() }

                Log.d(TAG, "‚úÖ Ses ba≈üarƒ±yla √ºretildi. Boyut: ${audioData.size}")
                playAudio(audioData)

            } catch (e: Throwable) {
                Log.e(TAG, "‚ùå Sentezleme sƒ±rasƒ±nda hata!", e)
            }
        }
    }

    private fun playAudio(audioData: FloatArray) {
        val sampleRate = 24000 // Bu model 24kHz ile eƒüitilmi≈ü
        val bufferSize = AudioTrack.getMinBufferSize(sampleRate, AudioFormat.CHANNEL_OUT_MONO, AudioFormat.ENCODING_PCM_FLOAT)
        audioTrack?.stop()
        audioTrack?.release()
        audioTrack = AudioTrack.Builder()
            .setAudioAttributes(
                AudioAttributes.Builder()
                    .setUsage(AudioAttributes.USAGE_MEDIA)
                    .setContentType(AudioAttributes.CONTENT_TYPE_SPEECH)
                    .build()
            )
            .setAudioFormat(
                AudioFormat.Builder()
                    .setEncoding(AudioFormat.ENCODING_PCM_FLOAT)
                    .setSampleRate(sampleRate)
                    .setChannelMask(AudioFormat.CHANNEL_OUT_MONO)
                    .build()
            )
            .setBufferSizeInBytes(bufferSize * 2)
            .setTransferMode(AudioTrack.MODE_STREAM)
            .build()

        try {
            audioTrack?.play()
            audioTrack?.write(audioData, 0, audioData.size, AudioTrack.WRITE_BLOCKING)
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå AudioTrack sesi √ßalarken hata olu≈ütu!", e)
        }
    }
}